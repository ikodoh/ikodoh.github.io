<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Large Language Models are Temporal and Causal Reasoners for Video Question Answering</title>
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 style="font-size: 44px;" class="title is-1 publication-title">Large Language Models are Temporal and Causal Reasoners for Video Question Answering</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://ikodoh.github.io">Dohwan Ko</a><sup>1*</sup>,</span>
            <span class="author-block">Ji Soo Lee<sup>1*</sup>,</span>
            <span class="author-block">Wooyoung Kang<sup>2</sup>,</span>
            <span class="author-block">Byungseok Roh<sup>2</sup>,</span>
            <span class="author-block">Hyunwoo J. Kim<sup>2</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Department of Computer Science and Engineering, Korea University</span>
            <span class="author-block"><sup>2</sup>Kakao Brain</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2310.15747"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.15747"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mlvlab/flipped-vqa"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <hr>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Language Models (LLMs) have shown remarkable performances on a wide range of natural language understanding and generation tasks. 
            We observe that the LLMs provide effective priors in exploiting linguistic shortcuts for temporal and causal reasoning in Video Question Answering (VideoQA). 
            However, such priors often cause suboptimal results on VideoQA by leading the model to overrely on questions, i.e., linguistic bias, while ignoring visual content. 
            This is also known as 'ungrounded guesses' or 'hallucinations'. 
            To address this problem while leveraging LLMs’ prior on VideoQA, we propose a novel framework, Flipped-VQA, encouraging the model 
            to predict all the combinations of ⟨V, Q, A⟩ triplet by flipping the source pair and the target label to understand their complex relationships, 
            i.e., predict A, Q, and V given a VQ, VA, and QA pairs, respectively. 
            In this paper, we develop LLaMA-VQA by applying Flipped-VQA to LLaMA, and it outperforms both LLMs-based and non-LLMs-based models on five challenging VideoQA benchmarks. 
            Furthermore, our Flipped-VQA is a general framework that is applicable to various LLMs (OPT and GPT-J) and consistently improves their performances. 
            We empirically demonstrate that Flipped-VQA not only enhances the exploitation of linguistic shortcuts but also mitigates the linguistic bias, 
            which causes incorrect answers over-relying on the question. 
            Code is available at https://github.com/mlvlab/Flipped-VQA.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
  <hr>
    <div class="hero-body">
      <img src="./images/publications/flipped_vqa.png"/>
      <h2 class="subtitle has-text-centered">
        <span>Illustration of LLMs with Flipped-VQA.</span>
      </h2>
    </div>
  </div>
</section>

<section class="section">
  
  <div class="container is-max-desktop">
    <h2 class="title is-3">Exploiting Linguistic Shortcut</h2>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h3 style="margin: 2px" class="title">Question:</h3>
          <p>Why did the man in white hold tightly to the boy in white?</p>
          <h3 style="margin: 2px" class="title">Choices:</h3>
          <form method="get" action="flipped_vqa_demo.html" id="Form1">
            <label><input type="radio" name="answer" value="c1"> 1. forcing boy to look straightsss<br></label>
            <label><input type="radio" name="answer" value="c2"> 2. boy keeps moving around<br></label>
            <label><input type="radio" name="answer" value="c3"> 3. posing for camera<br></label>
            <label><input type="radio" name="answer" value="c4"> 4. prevent falling off<br></label>
            <label><input type="radio" name="answer" value="c5"> 5. dancing with boy<br></label>
            <p><input type="submit" value="Submit" id="valuesubmit"> <input type="reset" value="Reset"></p>
          </form>
        </div>
      </div>

      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <button class="button is-success is-light" id="toggleButton1">Show Answer</button>
            <button class="button is-warning is-light" id="toggleButton2">Show Video</button>
            <p id="answer1" style="display: none;">Answer: 4. prevent falling off</p>
            <video id="video1" autoplay controls muted playsinline height="100%" style="display: none;">
              <source src="./static/flipped_vqa/video1.mp4" type="video/mp4">
            </video>
            
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->
    
  <div class="container is-max-desktop">
    <hr>

      <div class="columns is-centered">
        <div class="content">
        <h2 class="title">Exploiting Linguistic Shortcut</h2>
          <h3 style="margin: auto" class="title">Question:</h3>
          <p>Why did the man in white hold tightly to the boy in white?</p>
          <h3 style="margin: auto" class="title">Choices:</h3>
          <form method="get" action="flipped_vqa_demo.html">
            <label><input type="radio" name="answer" value="c1"> 1. forcing boy to look straightsss<br></label>
            <label><input type="radio" name="answer" value="c2"> 2. boy keeps moving around<br></label>
            <label><input type="radio" name="answer" value="c3"> 3. posing for camera<br></label>
            <label><input type="radio" name="answer" value="c4"> 4. prevent falling off<br></label>
            <label><input type="radio" name="answer" value="c5"> 5. dancing with boy<br></label>
            <p><input type="submit" value="Submit"> <input type="reset" value="Reset"></p>
          </form>
            <!-- <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/flipped_vqa/video1.mp4"
                      type="video/mp4">
            </video> -->
          </div>
        </div>
  

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Exploiting Linguistic Shortcut</h2>

        <h3 style="margin: auto;" class="title is-4">Question:</h3>
        <div class="content has-text-justified">
          <p>
            Why did the man in white hold tightly to the boy in white?
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{ko2023large,
  title     = {Large Language Models are Temporal and Causal Reasoners for Video Question Answering},
  author    = {Dohwan Ko and Ji Soo Lee and Wooyoung Kang and Byungseok Roh and Hyunwoo J. Kim},
  booktitle = {EMNLP},
  year      = {2023}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script>
  document.getElementById('toggleButton1').addEventListener('click', function() {
    var answerElement = document.getElementById('answer1');
    if (answerElement.style.display === 'none') {
      answerElement.style.display = 'block';
      document.getElementById('toggleButton1').textContent = 'Hide Answer';
    } else {
      answerElement.style.display = 'none';
      document.getElementById('toggleButton1').textContent = 'Show Answer';
    }
  });

  document.getElementById('toggleButton2').addEventListener('click', function() {
    var videoElement = document.getElementById('video1');
    if (videoElement.style.display === 'none') {
      videoElement.style.display = 'block';
      document.getElementById('toggleButton2').textContent = 'Hide Video';
    } else {
      videoElement.style.display = 'none';
      document.getElementById('toggleButton2').textContent = 'Show Video';
    }
  });

</script> 

</body>
</html>
