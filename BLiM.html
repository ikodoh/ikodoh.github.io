<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ST-VLM: Kinematic Instruction Tuning for Spatio-Temporal Reasoning in Vision-Language Models</title>
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 style="font-size: 40px;" class="title is-1 publication-title">Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://ikodoh.github.io">Dohwan Ko</a><sup>1*</sup>,</span>
            <span class="author-block">Ji Soo Lee<sup>1*</sup>,</span>
            <span class="author-block">Minhyuk Choi<sup>1*</sup>,</span>
            <span class="author-block"><a href="https://pages.cs.wisc.edu/~zihangm/">Zihang Meng</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://mlv.kaist.ac.kr">Hyunwoo J. Kim</a><sup>3</sup>,</span>
          </div>
          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Korea University</span>&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Meta GenAI</span>&nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>KAIST</span>
          </div>
          <br>
          <div class="is-size-4 publication-venue" style="text-align: center; margin: 0 auto;">ICCV 2025 Highlight</div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2507.23284"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.23284"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/mlvlab/BLiM"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (soon)</span>
                </a>
              </span>
              <!-- Hugging Face Link - Option 3: Using an image -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/ikodoh/BLiM-Data"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <img src="./images/logo/huggingface.svg" alt="Huggingface model">
                  </span>
                  <span>BLiM-Data</span>
                </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <hr>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Text-Video Retrieval aims to find the most relevant text (or video) candidate given a video (or text) query from largescale online databases. 
            Recent work leverages multi-modal large language models (MLLMs) to improve retrieval, especially for long or complex query-candidate pairs. 
            However, we observe that the naive application of MLLMs, i.e., retrieval based on candidate likelihood, introduces candidate prior bias, favoring candidates with inherently higher priors over those more relevant to the query. 
            To this end, we propose a novel retrieval framework, Bidirectional Likelihood Estimation with MLLM (BLiM), which leverages both query and candidate likelihoods by training the model to generate text from a given video as well as video features from a given text. 
            Furthermore, we introduce Candidate Prior Normalization (CPN), a simple yet effective training-free score calibration module designed to mitigate candidate prior bias in candidate likelihood. 
            On four TextVideo Retrieval benchmarks, our BLiM equipped with CPN outperforms previous state-of-the-art models by 6.4 R@1 on average, effectively alleviating candidate prior bias and emphasizing query-candidate relevance. 
            Our in-depth analysis across various multi-modal tasks beyond retrieval highlights the broad applicability of CPN which enhances visual understanding by reducing reliance on textual priors.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
  <hr>
    <div class="hero-body">
      <img src="./images/publications/blim.png"/>
      <h2 class="subtitle has-text-centered">
        <span><strong>Illustration of BLiM.</strong></span>
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser"> 
  <div class="container is-max-desktop">
  <hr>
    <div class="hero-body">
      <img src="./images/projects/blim/result.png"/>
      <h2 class="subtitle has-text-centered">
        <span><strong>Results of BLiM on Text-Video Retrieval benchmarks.</strong></span>
      </h2>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
