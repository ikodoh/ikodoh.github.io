---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I'm Dohwan Ko, a Ph.D. student at <a href="https://mlv.kaist.ac.kr/" style="color: #900023; text-decoration: none;">**Machine Learning and Vision Lab (MLV)**</a> in Korea University, under the supervision of Prof.  <a href="https://pages.cs.wisc.edu/~hwkim/" style="color: #900023; text-decoration: none;">**Hyunwoo J. Kim**</a>. 
I received my B.S. degree in Computer Science and Engineering in Korea University at Feb. 2021.
My research interest includes:
- Multi-modal Understanding
- Video Understanding
- Foundation Models
- Large Language Models
- Self-supervised Learning

Here is my <a href="../cv.pdf" style="color: #900023; text-decoratio.n: none;">**CV**</a>.  (last update: Jun. 2025).

## Education
- **M.S & Ph.D** in Computer Science and Engineering at <a href="https://www.korea.edu/mbshome/mbs/en/index.do" style="color: #900023; text-decoratio.n: none;">**Korea University**</a>. \\
Mar. 2021 - Current

- **B.S.** in Computer Science and Engineering at <a href="https://www.korea.edu/mbshome/mbs/en/index.do" style="color: #900023; text-decoration.n: none;">**Korea University**</a>. \\
Mar. 2017 - Feb. 2021

## Work Experiences
- <img src="../images/logo/meta.png" alt="Meta logo" style="height: 1em;"> **Meta** \\
Menlo Park, CA, USA (Mar. 2025 - Jun. 2025)  \\
Research Scientist Intern in Meta Reality Lab. 

- <img src="../images/logo/nec.png" alt="NEC logo" style="height: 2em;"> **NEC Labs America** \\
San Jose, CA, USA (Jun. 2024 - Aug. 2024) \\
Research Scientist Intern in Media Analytics Team. 

- <img src="../images/logo/naver.png" alt="NAVER logo" style="height: 1em;"> **NAVER** \\
Seongnam, South Korea (Jul. 2020 - Aug. 2020) \\
Internship at User Feedback Platform. 

## News
<div class="news-item">
  <span class="news-date">Jun. 2025</span>&nbsp;&nbsp;
  <span class="news-content">Our paper <strong>Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval</strong> has been accepted to ICCV 2025!</span>
</div>

<div class="news-item">
  <span class="news-date">Sep. 2024</span>&nbsp;&nbsp;
  <span class="news-content">Our paper <strong>LLaMo: Large Language Model-based Molecular Graph Assistant</strong> has been accepted to NeurIPS 2024!</span>
</div>

<div class="news-item">
  <span class="news-date">Oct. 2023</span>&nbsp;&nbsp;
  <span class="news-content">Our paper <strong>Large Language Models are Temporal and Causal Reasoners for Video Question Answering</strong> has been accepted to EMNLP 2023!</span>
</div>

<div class="news-item">
  <span class="news-date">Jul. 2023</span>&nbsp;&nbsp;
  <span class="news-content">Our paper <strong>Open-vocabulary Video Question Answering (OVQA)</strong> has been accepted to ICCV 2023!</span>
</div>

<div class="news-item">
  <span class="news-date">Feb. 2023</span>&nbsp;&nbsp;
  <span class="news-content">Our paper <strong>Meta Loss Transformer (MELTR)</strong> has been accepted to CVPR 2023!</span>
</div>

<div class="news-item">
  <span class="news-date">Nov. 2022</span>&nbsp;&nbsp;
  <span class="news-content">Our paper <strong>Randomly Shuffled Convolution for Self-Supervised Representation Learning (Croffle)</strong> has been accepted to Information Sciences!</span>
</div>

<div class="news-item">
  <span class="news-date">Mar. 2022</span>&nbsp;&nbsp;
  <span class="news-content">Our paper <strong>Video-Text Representation Learning via Differentiable Weak Alignment (VT-TWINS)</strong> has been accepted to CVPR 2022!</span>
</div>

<div class="news-item">
  <span class="news-date">Oct. 2021</span>&nbsp;&nbsp;
  <span class="news-content">Our paper <strong>Search-and-Attack: Temporally Sparse Adversarial Perturbations on Videos</strong> has been accepted to IEEE Access!</span>
</div>

<style>
.news-item {
  display: flex;
  margin-bottom: 10px;
  align-items: baseline;
}

.news-date {
  min-width: 80px;
  font-weight: bold;
  color: #900023;
}

.news-content {
  flex: 1;
}
</style>