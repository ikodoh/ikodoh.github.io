---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

## International Conference Publications
<div class="row">
	<div class="col-xs-10 col-sm-4 col-md-4" style="height:120px">
		<a class="thumbnail"><img src="../images/publications/flipped_vqa.png" height="100%" alt="VidChapters-7M: Video Chapters at Scale"></a>
	</div>
  <div class="col-xs-12 col-sm-8 col-md-8">
    <strong>Large Language Models are Temporal and Causal Reasoners for Video Question Answering</strong> <br>
    <span style="font-size: medium;"><u><strong>Dohwan Ko</strong></u>*, Ji Soo Lee*, Wooyoung Kang, Byungseok Roh, Hyunwoo J. Kim<br></span>
    <div style="font-size: medium; color: #2980f1;"><strong>EMNLP 2023 Main</strong></div>
    <a href="https://arxiv.org/abs/2310.15747"><button type="button" style="color: #fff; background-color: rgb(139, 193, 229); border-color: transparent;" class="btn btn-primary btn-sm">arxiv</button></a>
    <a href="https://github.com/mlvlab/Flipped-VQA"><button type="button" style="color: #fff; background-color: #95ADB6; border-color: transparent;" class="btn btn-primary btn-sm">code</button></a>
    <a href="../flipped_vqa.html"><button type="button" style="color: #fff; background-color: rgb(139, 229, 154); border-color: transparent;" class="btn btn-primary btn-sm">project page</button></a>
    <button type="button" style="color: #fff; background-color: #DBC7BE; border-color: transparent;" class="btn btn-primary btn-sm" data-toggle="collapse" data-target="#emnlp2023">bibtex</button>
      <div id="emnlp2023" class="collapse">
        <pre><tt>@inproceedings{ko2023large,
        title={Large Language Models are Temporal and Causal Reasoners for Video Question Answering},
        author={Dohwan Ko and Ji Soo Lee and Wooyoung Kang and Byungseok Roh and Hyunwoo J. Kim},
        booktitle={EMNLP},
        year={2023}}</tt></pre>
      </div>
    <span></span>
  </div>
</div>
<hr>

<div class="row">
	<div class="col-xs-10 col-sm-4 col-md-4" style="height:120px">
		<a class="thumbnail"><img src="../images/publications/ovqa.png" height="100%" alt="VidChapters-7M: Video Chapters at Scale"></a>
	</div>
  <div class="col-xs-12 col-sm-8 col-md-8">
    <strong>Open-Vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models</strong> <br>
    <span style="font-size: medium;"><u><strong>Dohwan Ko</strong></u>, Ji Soo Lee, Miso Choi, Jaewon Chu, Jihwan Park, Hyunwoo J. Kim<br></span>
    <div style="font-size: medium; color: #2980f1;"><strong>ICCV 2023</strong></div>
    <a href="https://arxiv.org/abs/2308.09363"><button type="button" style="color: #fff; background-color: rgb(139, 193, 229); border-color: transparent;" class="btn btn-primary btn-sm">arxiv</button></a>
    <a href="https://github.com/mlvlab/OVQA"><button type="button" style="color: #fff; background-color: #95ADB6; border-color: transparent;" class="btn btn-primary btn-sm">code</button></a>
    <button type="button" style="color: #fff; background-color: #DBC7BE; border-color: transparent;" class="btn btn-primary btn-sm" data-toggle="collapse" data-target="#iccv2023">bibtex</button>
      <div id="iccv2023" class="collapse">
        <pre><tt>@inproceedings{ko2023open,
        title={Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models},
        author={Ko, Dohwan and Lee, Ji Soo and Choi, Miso and Chu, Jaewon and Park, Jihwan and Kim, Hyunwoo J},
        booktitle={ICCV},
        year={2023}}</tt></pre>
      </div>
    <span></span>
  </div>
</div>
<hr>

<div class="row">
	<div class="col-xs-10 col-sm-4 col-md-4" style="height:120px">
		<a class="thumbnail"><img src="../images/publications/meltr.png" height="100%" alt="VidChapters-7M: Video Chapters at Scale"></a>
	</div>
  <div class="col-xs-12 col-sm-8 col-md-8">
    <strong>MELTR: Meta Loss Transformer for Learning to Fine-tune Video Foundation Models</strong> <br>
    <span style="font-size: medium;"><u><strong>Dohwan Ko</strong></u>*, Joonmyung Choi*, Hyeong Kyu Choi, Kyoung-Woon On, Byungseok Roh, Hyunwoo J. Kim<br></span>
    <div style="font-size: medium; color: #2980f1;"><strong>CVPR 2023</strong></div>
    <a href="https://arxiv.org/abs/2303.13009"><button type="button" style="color: #fff; background-color: rgb(139, 193, 229); border-color: transparent;" class="btn btn-primary btn-sm">arxiv</button></a>
    <a href="https://github.com/mlvlab/MELTR"><button type="button" style="color: #fff; background-color: #95ADB6; border-color: transparent;" class="btn btn-primary btn-sm">code</button></a>
    <button type="button" style="color: #fff; background-color: #DBC7BE; border-color: transparent;" class="btn btn-primary btn-sm" data-toggle="collapse" data-target="#cvpr2023">bibtex</button>
      <div id="cvpr2023" class="collapse">
        <pre><tt>@inproceedings{ko2023melrt,
        title={MELTR: Meta Loss Transformer for Learning to Fine-tune Video Foundation Models},
        author={Ko, Dohwan and Choi, Joonmyung and Choi, Hyeong Kyu and On, Kyoung-Woon and Roh, Byungseok and Kim, Hyunwoo J},
        booktitle={CVPR},
        year={2023}}</tt></pre>
      </div>
    <span></span>
  </div>
</div>
<hr>

<div class="row">
	<div class="col-xs-10 col-sm-4 col-md-4" style="height:120px">
		<a class="thumbnail"><img src="../images/publications/vt_twins.png" height="100%" alt="VidChapters-7M: Video Chapters at Scale"></a>
	</div>
  <div class="col-xs-12 col-sm-8 col-md-8">
    <strong>Video-Text Representation Learning via Differentiable Weak Temporal Alignment</strong> <br>
    <span style="font-size: medium;"><u><strong>Dohwan Ko</strong></u>, Joonmyung Choi, Juyeon Ko, Shinyeong Noh, Kyoung-Woon On, Eun-Sol Kim, Hyunwoo J. Kim<br></span>
    <div style="font-size: medium; color: #2980f1;"><strong>CVPR 2022</strong></div>
    <a href="https://arxiv.org/abs/2203.16784"><button type="button" style="color: #fff; background-color: rgb(139, 193, 229); border-color: transparent;" class="btn btn-primary btn-sm">arxiv</button></a>
    <a href="https://github.com/mlvlab/VT-TWINS"><button type="button" style="color: #fff; background-color: #95ADB6; border-color: transparent;" class="btn btn-primary btn-sm">code</button></a>
    <button type="button" style="color: #fff; background-color: #DBC7BE; border-color: transparent;" class="btn btn-primary btn-sm" data-toggle="collapse" data-target="#cvpr2022">bibtex</button>
      <div id="cvpr2022" class="collapse">
        <pre><tt>@inproceedings{ko2022video,
        title={Video-Text Representation Learning via Differentiable Weak Temporal Alignment},
        author={Ko, Dohwan and Choi, Joonmyung and Ko, Juyeon and Noh, Shinyeong and On, Kyoung-Woon and Kim, Eun-Sol and Kim, Hyunwoo J},
        booktitle={CVPR},
        year={2022}}</tt></pre>
      </div>
    <span></span>
  </div>
</div>
<hr>


## International Journal Publications
<div class="row">
	<div class="col-xs-10 col-sm-4 col-md-4" style="height:120px">
		<a class="thumbnail"><img src="../images/publications/croffle.png" height="100%" alt="VidChapters-7M: Video Chapters at Scale"></a>
	</div>
  <div class="col-xs-12 col-sm-8 col-md-8">
    <strong>Randomly Shuffled Convolution for Self-Supervised Representation Learning</strong> <br>
    <span style="font-size: medium;">Youngjin Oh*, Minkyu Jeon*, <u><strong>Dohwan Ko</strong></u>, Hyunwoo J. Kim<br></span>
    <div style="font-size: medium; color: #2980f1;"><strong>Information Sciences 2023</strong></div>
    <a href="https://www.sciencedirect.com/science/article/pii/S0020025522013032"><button type="button" style="color: #fff; background-color: rgb(139, 193, 229); border-color: transparent;" class="btn btn-primary btn-sm">paper</button></a>
    <button type="button" style="color: #fff; background-color: #DBC7BE; border-color: transparent;" class="btn btn-primary btn-sm" data-toggle="collapse" data-target="#info2023">bibtex</button>
      <div id="info2023" class="collapse">
        <pre><tt>@article{oh2023randomly,
        title={Randomly shuffled convolution for self-supervised representation learning},
        author={Oh, Youngjin and Jeon, Minkyu and Ko, Dohwan and Kim, Hyunwoo J},
        journal={Information Sciences},
        year={2023}}</tt></pre>
      </div>
    <span></span>
  </div>
</div>
<hr>

<div class="row">
	<div class="col-xs-10 col-sm-4 col-md-4" style="height:120px">
		<a class="thumbnail"><img src="../images/publications/search_and_attack.png" height="100%" alt="VidChapters-7M: Video Chapters at Scale"></a>
	</div>
  <div class="col-xs-12 col-sm-8 col-md-8">
    <strong>Search-and-Attack: Temporally SparseAdversarial Perturbations on Videos</strong><br>
    <span style="font-size: medium;">Hwan Heo*, <u><strong>Dohwan Ko</strong></u>*, Jaewon Lee*, Youngjoon Hong, Hyunwoo J. Kim<br></span>
    <div style="font-size: medium; color: #2980f1;"><strong>IEEE Access 2021</strong></div>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9592758&tag=1"><button type="button" style="color: #fff; background-color: rgb(139, 193, 229); border-color: transparent;" class="btn btn-primary btn-sm">paper</button></a>
    <button type="button" style="color: #fff; background-color: #DBC7BE; border-color: transparent;" class="btn btn-primary btn-sm" data-toggle="collapse" data-target="#access2021">bibtex</button>
      <div id="access2021" class="collapse">
        <pre><tt>@article{heo2021search,
        title={Search-and-attack: temporally sparse adversarial perturbations on videos},
        author={Heo, Hwan and Ko, Dohwan and Lee, Jaewon and Hong, Youngjoon and Kim, Hyunwoo J},
        journal={IEEE Access},
        year={2021}}</tt></pre>
      </div>
    <span></span>
  </div>
</div>
<hr>